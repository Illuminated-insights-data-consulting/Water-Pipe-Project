{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as datetime\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier, StackingClassifier, RandomForestClassifier, BaggingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support, balanced_accuracy_score, plot_precision_recall_curve, precision_recall_curve, precision_score, recall_score\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['OBJECTID', 'Join_Count', 'Join_Count_1',\n       'FID_DWW_Mainlines__Permitted_Use__Pipe_widths',\n       'DWW_Mainlines__Permitted_Use__MNL_FEA_KE',\n       'DWW_Mainlines__Permitted_Use__MNL_FEAT_1',\n       'DWW_Mainlines__Permitted_Use__MNL_OWNE_1',\n       'DWW_Mainlines__Permitted_Use__MNL_MATE_1',\n       'DWW_Mainlines__Permitted_Use__MNL_LENGTH',\n       'DWW_Mainlines__Permitted_Use__MNL_INSTAL', 'Pipe_widths_MNL_FEA_KEY',\n       'Pipe_widths_Width', 'FID_SeaSoilClip', 'MUSYM', 'MUKEY', 'muname',\n       'ARTCLASS', 'UNITDESC', 'STNAME_ORD', 'BLOCKNBR', 'SPEEDLIMIT',\n       'SURFACEWID', 'SURFACETYP', 'SLOPE_PCT', 'NEAR_DIST', 'NEAR_X',\n       'NEAR_Y', 'WONUM', 'ASSETNUM', 'Size', 'Long', 'Lat', 'DATE'],\n      dtype='object')\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   OBJECTID DWW_Mainlines__Permitted_Use__MNL_FEAT_1  \\\n",
       "0         1                                 Mainline   \n",
       "1         2                                 Mainline   \n",
       "2         3                                 Mainline   \n",
       "3         4                                 Mainline   \n",
       "4         5                                 Mainline   \n",
       "5         6                                 Mainline   \n",
       "6         7                                 Mainline   \n",
       "7         8                                     Stub   \n",
       "8         9                                     Stub   \n",
       "9        10                                 Mainline   \n",
       "\n",
       "  DWW_Mainlines__Permitted_Use__MNL_MATE_1  \\\n",
       "0                                 Concrete   \n",
       "1                                 Concrete   \n",
       "2                                 Concrete   \n",
       "3                           Vitrified Clay   \n",
       "4                 Reinforced Concrete Pipe   \n",
       "5                                 Concrete   \n",
       "6                 Reinforced Concrete Pipe   \n",
       "7                                 Concrete   \n",
       "8                                 Concrete   \n",
       "9                                 Concrete   \n",
       "\n",
       "   DWW_Mainlines__Permitted_Use__MNL_LENGTH  \\\n",
       "0                                    314.79   \n",
       "1                                    363.39   \n",
       "2                                    323.51   \n",
       "3                                    329.13   \n",
       "4                                    273.64   \n",
       "5                                     30.87   \n",
       "6                                    112.29   \n",
       "7                                     29.89   \n",
       "8                                      7.49   \n",
       "9                                     42.59   \n",
       "\n",
       "  DWW_Mainlines__Permitted_Use__MNL_INSTAL  Pipe_widths_Width    NEAR_DIST  \\\n",
       "0                         1/1/1972 0:00:00                8.0  3964.600720   \n",
       "1                         1/1/1972 0:00:00                8.0  3609.210948   \n",
       "2                         1/1/1972 0:00:00                8.0  3451.254435   \n",
       "3                         1/1/1928 0:00:00               12.0   833.915482   \n",
       "4                         1/1/1928 0:00:00               18.0   852.426502   \n",
       "5                         1/1/1963 0:00:00                8.0  1404.924372   \n",
       "6                         1/1/1990 0:00:00               18.0  2212.976394   \n",
       "7                         1/1/1958 0:00:00                8.0  3065.662515   \n",
       "8                         1/1/1958 0:00:00                8.0  3148.924667   \n",
       "9                         1/1/1958 0:00:00                8.0  3196.074038   \n",
       "\n",
       "   MUSYM  ARTCLASS  BLOCKNBR  SPEEDLIMIT  SURFACEWID SURFACETYP  SLOPE_PCT  \\\n",
       "0   3055       2.0    9400.0        25.0        40.0        PCC        0.0   \n",
       "1   3056       0.0       0.0        20.0        46.0         AC        4.0   \n",
       "2   3056       0.0       0.0        20.0        46.0         AC        4.0   \n",
       "3   3056       0.0    5100.0        20.0         0.0         ST        6.0   \n",
       "4   3056       2.0   10300.0        25.0        42.0     AC/PCC        4.0   \n",
       "5   3056       0.0     400.0        20.0        23.0         AC        3.0   \n",
       "6    988       0.0    1200.0        20.0        22.0         ST        2.0   \n",
       "7   3055       0.0    2200.0        20.0        21.0         ST        1.0   \n",
       "8   3055       0.0    2300.0        20.0        21.0         ST        2.0   \n",
       "9   3059       0.0     200.0        20.0        18.0         ST       11.0   \n",
       "\n",
       "  Size DATE  \n",
       "0  NaN  NaN  \n",
       "1  NaN  NaN  \n",
       "2  NaN  NaN  \n",
       "3  NaN  NaN  \n",
       "4  NaN  NaN  \n",
       "5  NaN  NaN  \n",
       "6  NaN  NaN  \n",
       "7  NaN  NaN  \n",
       "8  NaN  NaN  \n",
       "9  NaN  NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OBJECTID</th>\n      <th>DWW_Mainlines__Permitted_Use__MNL_FEAT_1</th>\n      <th>DWW_Mainlines__Permitted_Use__MNL_MATE_1</th>\n      <th>DWW_Mainlines__Permitted_Use__MNL_LENGTH</th>\n      <th>DWW_Mainlines__Permitted_Use__MNL_INSTAL</th>\n      <th>Pipe_widths_Width</th>\n      <th>NEAR_DIST</th>\n      <th>MUSYM</th>\n      <th>ARTCLASS</th>\n      <th>BLOCKNBR</th>\n      <th>SPEEDLIMIT</th>\n      <th>SURFACEWID</th>\n      <th>SURFACETYP</th>\n      <th>SLOPE_PCT</th>\n      <th>Size</th>\n      <th>DATE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Mainline</td>\n      <td>Concrete</td>\n      <td>314.79</td>\n      <td>1/1/1972 0:00:00</td>\n      <td>8.0</td>\n      <td>3964.600720</td>\n      <td>3055</td>\n      <td>2.0</td>\n      <td>9400.0</td>\n      <td>25.0</td>\n      <td>40.0</td>\n      <td>PCC</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Mainline</td>\n      <td>Concrete</td>\n      <td>363.39</td>\n      <td>1/1/1972 0:00:00</td>\n      <td>8.0</td>\n      <td>3609.210948</td>\n      <td>3056</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n      <td>46.0</td>\n      <td>AC</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Mainline</td>\n      <td>Concrete</td>\n      <td>323.51</td>\n      <td>1/1/1972 0:00:00</td>\n      <td>8.0</td>\n      <td>3451.254435</td>\n      <td>3056</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n      <td>46.0</td>\n      <td>AC</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Mainline</td>\n      <td>Vitrified Clay</td>\n      <td>329.13</td>\n      <td>1/1/1928 0:00:00</td>\n      <td>12.0</td>\n      <td>833.915482</td>\n      <td>3056</td>\n      <td>0.0</td>\n      <td>5100.0</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>ST</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Mainline</td>\n      <td>Reinforced Concrete Pipe</td>\n      <td>273.64</td>\n      <td>1/1/1928 0:00:00</td>\n      <td>18.0</td>\n      <td>852.426502</td>\n      <td>3056</td>\n      <td>2.0</td>\n      <td>10300.0</td>\n      <td>25.0</td>\n      <td>42.0</td>\n      <td>AC/PCC</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>Mainline</td>\n      <td>Concrete</td>\n      <td>30.87</td>\n      <td>1/1/1963 0:00:00</td>\n      <td>8.0</td>\n      <td>1404.924372</td>\n      <td>3056</td>\n      <td>0.0</td>\n      <td>400.0</td>\n      <td>20.0</td>\n      <td>23.0</td>\n      <td>AC</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>Mainline</td>\n      <td>Reinforced Concrete Pipe</td>\n      <td>112.29</td>\n      <td>1/1/1990 0:00:00</td>\n      <td>18.0</td>\n      <td>2212.976394</td>\n      <td>988</td>\n      <td>0.0</td>\n      <td>1200.0</td>\n      <td>20.0</td>\n      <td>22.0</td>\n      <td>ST</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>Stub</td>\n      <td>Concrete</td>\n      <td>29.89</td>\n      <td>1/1/1958 0:00:00</td>\n      <td>8.0</td>\n      <td>3065.662515</td>\n      <td>3055</td>\n      <td>0.0</td>\n      <td>2200.0</td>\n      <td>20.0</td>\n      <td>21.0</td>\n      <td>ST</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>Stub</td>\n      <td>Concrete</td>\n      <td>7.49</td>\n      <td>1/1/1958 0:00:00</td>\n      <td>8.0</td>\n      <td>3148.924667</td>\n      <td>3055</td>\n      <td>0.0</td>\n      <td>2300.0</td>\n      <td>20.0</td>\n      <td>21.0</td>\n      <td>ST</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>Mainline</td>\n      <td>Concrete</td>\n      <td>42.59</td>\n      <td>1/1/1958 0:00:00</td>\n      <td>8.0</td>\n      <td>3196.074038</td>\n      <td>3059</td>\n      <td>0.0</td>\n      <td>200.0</td>\n      <td>20.0</td>\n      <td>18.0</td>\n      <td>ST</td>\n      <td>11.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "df = pd.read_csv(\"Pipes_Break20.csv\")\n",
    "\n",
    "print(df.columns)\n",
    "# # select non join columns and ML needed columns\n",
    "columns = ['OBJECTID', 'DWW_Mainlines__Permitted_Use__MNL_FEAT_1', 'DWW_Mainlines__Permitted_Use__MNL_MATE_1', \n",
    "       'DWW_Mainlines__Permitted_Use__MNL_LENGTH', 'DWW_Mainlines__Permitted_Use__MNL_INSTAL',\n",
    "       'Pipe_widths_Width', 'NEAR_DIST', 'MUSYM', 'ARTCLASS', 'BLOCKNBR',\n",
    "       'SPEEDLIMIT', 'SURFACEWID', 'SURFACETYP', 'SLOPE_PCT', 'Size', 'DATE']\n",
    "non_joins = df[columns]\n",
    "non_joins.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2800\n1951\nduplicate breaks:  849\n"
     ]
    }
   ],
   "source": [
    "ddff = non_joins[non_joins['DATE'].notna()]\n",
    "print(len(ddff['DATE']))\n",
    "print(len(ddff['DATE'].unique()))\n",
    "print('duplicate breaks: ', len(ddff['DATE']) - len(ddff['DATE'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This line removes duplicate breaks, based on the date column. \n",
    "non_joins = non_joins[(~non_joins['DATE'].duplicated() | df['DATE'].isnull())]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   OBJECTID DWW_Mainlines__Permitted_Use__MNL_FEAT_1  \\\n",
       "0         1                                 Mainline   \n",
       "1         2                                 Mainline   \n",
       "2         3                                 Mainline   \n",
       "3         4                                 Mainline   \n",
       "4         5                                 Mainline   \n",
       "\n",
       "  DWW_Mainlines__Permitted_Use__MNL_MATE_1  \\\n",
       "0                                 Concrete   \n",
       "1                                 Concrete   \n",
       "2                                 Concrete   \n",
       "3                           Vitrified Clay   \n",
       "4                 Reinforced Concrete Pipe   \n",
       "\n",
       "   DWW_Mainlines__Permitted_Use__MNL_LENGTH  \\\n",
       "0                                    314.79   \n",
       "1                                    363.39   \n",
       "2                                    323.51   \n",
       "3                                    329.13   \n",
       "4                                    273.64   \n",
       "\n",
       "   DWW_Mainlines__Permitted_Use__MNL_INSTAL  Pipe_widths_Width    NEAR_DIST  \\\n",
       "0                                      1972                8.0  3964.600720   \n",
       "1                                      1972                8.0  3609.210948   \n",
       "2                                      1972                8.0  3451.254435   \n",
       "3                                      1928               12.0   833.915482   \n",
       "4                                      1928               18.0   852.426502   \n",
       "\n",
       "   MUSYM  ARTCLASS  BLOCKNBR  SPEEDLIMIT  SURFACEWID SURFACETYP  SLOPE_PCT  \\\n",
       "0   3055       2.0    9400.0        25.0        40.0        PCC        0.0   \n",
       "1   3056       0.0       0.0        20.0        46.0         AC        4.0   \n",
       "2   3056       0.0       0.0        20.0        46.0         AC        4.0   \n",
       "3   3056       0.0    5100.0        20.0         0.0         ST        6.0   \n",
       "4   3056       2.0   10300.0        25.0        42.0     AC/PCC        4.0   \n",
       "\n",
       "  Size  DATE  \n",
       "0  NaN   NaN  \n",
       "1  NaN   NaN  \n",
       "2  NaN   NaN  \n",
       "3  NaN   NaN  \n",
       "4  NaN   NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OBJECTID</th>\n      <th>DWW_Mainlines__Permitted_Use__MNL_FEAT_1</th>\n      <th>DWW_Mainlines__Permitted_Use__MNL_MATE_1</th>\n      <th>DWW_Mainlines__Permitted_Use__MNL_LENGTH</th>\n      <th>DWW_Mainlines__Permitted_Use__MNL_INSTAL</th>\n      <th>Pipe_widths_Width</th>\n      <th>NEAR_DIST</th>\n      <th>MUSYM</th>\n      <th>ARTCLASS</th>\n      <th>BLOCKNBR</th>\n      <th>SPEEDLIMIT</th>\n      <th>SURFACEWID</th>\n      <th>SURFACETYP</th>\n      <th>SLOPE_PCT</th>\n      <th>Size</th>\n      <th>DATE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Mainline</td>\n      <td>Concrete</td>\n      <td>314.79</td>\n      <td>1972</td>\n      <td>8.0</td>\n      <td>3964.600720</td>\n      <td>3055</td>\n      <td>2.0</td>\n      <td>9400.0</td>\n      <td>25.0</td>\n      <td>40.0</td>\n      <td>PCC</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Mainline</td>\n      <td>Concrete</td>\n      <td>363.39</td>\n      <td>1972</td>\n      <td>8.0</td>\n      <td>3609.210948</td>\n      <td>3056</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n      <td>46.0</td>\n      <td>AC</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Mainline</td>\n      <td>Concrete</td>\n      <td>323.51</td>\n      <td>1972</td>\n      <td>8.0</td>\n      <td>3451.254435</td>\n      <td>3056</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n      <td>46.0</td>\n      <td>AC</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Mainline</td>\n      <td>Vitrified Clay</td>\n      <td>329.13</td>\n      <td>1928</td>\n      <td>12.0</td>\n      <td>833.915482</td>\n      <td>3056</td>\n      <td>0.0</td>\n      <td>5100.0</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>ST</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Mainline</td>\n      <td>Reinforced Concrete Pipe</td>\n      <td>273.64</td>\n      <td>1928</td>\n      <td>18.0</td>\n      <td>852.426502</td>\n      <td>3056</td>\n      <td>2.0</td>\n      <td>10300.0</td>\n      <td>25.0</td>\n      <td>42.0</td>\n      <td>AC/PCC</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "# select only years\n",
    "non_joins['DWW_Mainlines__Permitted_Use__MNL_INSTAL'] = pd.to_datetime(non_joins['DWW_Mainlines__Permitted_Use__MNL_INSTAL'], format='%m/%d/%Y %H:%M:%S')\n",
    "non_joins['DWW_Mainlines__Permitted_Use__MNL_INSTAL'] = non_joins['DWW_Mainlines__Permitted_Use__MNL_INSTAL'].map(lambda x: x.year)\n",
    "\n",
    "non_joins['DATE'] = pd.to_datetime(non_joins['DATE'], format='%m/%d/%Y %H:%M:%S')\n",
    "non_joins['DATE'] = non_joins['DATE'].map(lambda x: x.year)\n",
    "\n",
    "non_joins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out NaN from DATE col\n",
    "breaks_df = non_joins[non_joins['DATE'].notna()]\n",
    "# set size column to width column and drop size \n",
    "breaks_df['Pipe_widths_Width'] = breaks_df['Size']\n",
    "breaks_df = breaks_df.drop('Size', axis=1)\n",
    "# breaks_df.head()"
   ]
  },
  {
   "source": [
    "## ML Pseudo Steps\n",
    "#### 1) assign binary variable --> can be raw data set\n",
    "#### 2) create dummy variables for categorical columns\n",
    "* make sure soil column ['MUSYM'] is categorical\n",
    "#### 3) list of years (and cycle through those)\n",
    "#### 4) will have six year groups :\n",
    "* train on [2009, 2010, 2011], test on [2012, 2013, 2014]\n",
    "* move onto [2010, 2011, 2012], test on [2013, 2014, 2015], etc ...\n",
    "#### 5) create function to create subset of data\n",
    "* want to include where there is NOT a break year (those will be our non-broken positive examples)\n",
    "* want to include where break year is in time frame of what we want\n",
    "* exclude installs AFTER time frame window\n",
    "* based on time window, calculate appropriate age of pipes \n",
    "    * (select beginning year of time frame --> ex: [2009, 2010, 2011] subtract install year from 2009)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_df = non_joins\n",
    "# pseudo_df.head()\n",
    "\n",
    "# fill Nan with 0 (idk why, but it just made it work FOR NOW)\n",
    "# if date is not 0 (NaN), make width = size \n",
    "# then for all df, drop size column\n",
    "\n",
    "pseudo_df['DATE'] = pseudo_df['DATE'].fillna(0)\n",
    "pseudo_df.loc[pseudo_df['DATE'] != 0, ['Pipe_widths_Width']] = pseudo_df['Size']\n",
    "pseudo_df = pseudo_df.drop('Size', axis=1)\n",
    "# pseudo_df.head()\n",
    "\n",
    "# change 'Width' values to numbers instead of strings (for dummy prep)\n",
    "pseudo_df['Width'] = pd.to_numeric(pseudo_df['Pipe_widths_Width'], errors='coerce')\n",
    "# pseudo_df['Width'].unique()\n",
    "\n",
    "# Assign binary variables:\n",
    "# [Create new column] If pipe has a broken date --> broken pipes = 0, non-broken pipes = 1\n",
    "pseudo_df['TARGET'] = pseudo_df['DATE'].apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables\n",
    "dummy_df = pd.get_dummies(pseudo_df)\n",
    "# test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df, start, end):\n",
    "    \"\"\"\n",
    "    Takes in df and filters depending on timeframe (start and end years).\n",
    "    Returns subset of data for training in timeframe.\n",
    "    \"\"\"\n",
    "    # want to include where there is NOT a break year (those will be our non-broken positive examples --> 'DATE' == 0) - DATE col\n",
    "    # want to include where break year is in time frame of what we want - DATE col\n",
    "    train_df = df[(df['DATE'] == 0 )| ((df['DATE'] >= start) & (df['DATE'] <= end))]\n",
    "\n",
    "    # exclude installs AFTER time frame window - MNL_INSTAL col\n",
    "    train_df = train_df[(train_df['DWW_Mainlines__Permitted_Use__MNL_INSTAL'] <= end)]\n",
    "\n",
    "    # based on time window, calculate appropriate age of pipes (select beginning year of time frame --> ex: 2009, 2010, 2011\n",
    "    #       subtract install year from 2009) - MNL_INSTAL col\n",
    "    # -- will create negative numbers\n",
    "    train_df['AGE'] = start - train_df['DWW_Mainlines__Permitted_Use__MNL_INSTAL']\n",
    "\n",
    "    return train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_data(dummy_df, 2009, 2011)\n",
    "# train_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trains\n",
    "# tests\n",
    "# move over\n",
    "# rinse & repeat until 2019\n",
    "def split_df(df):\n",
    "    \"\"\"\n",
    "    \"\"\"    \n",
    "    df = df.dropna()\n",
    "    feature_df = df.drop(['TARGET', 'DATE'], axis=1)\n",
    "    target_df = df[['TARGET']]\n",
    "\n",
    "    return feature_df, target_df\n",
    "\n",
    "def train_v1(df, model):\n",
    "    \"\"\"\n",
    "    Takes in a dataframe of interest and a model, and trains the model.\n",
    "    Model likely needs to be one imported from sklearn so it is able to\n",
    "    handle dataframes as input data\n",
    "    \"\"\"\n",
    "    feature, target = split_df(df)\n",
    "    clf = model #clf is for for classification\n",
    "    clf.fit(feature, target)\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "train_v1() missing 1 required positional argument: 'model'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-8b6c8e168d0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training data with ExtraTreesClassifier and split data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mextra_tree_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# running a prediction model on training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: train_v1() missing 1 required positional argument: 'model'"
     ]
    }
   ],
   "source": [
    "# Training data with ExtraTreesClassifier and split data\n",
    "extra_tree_model = train_v1(train_df)\n",
    "feature, target = split_df(train_df)\n",
    "\n",
    "# running a prediction model on training set\n",
    "training_pred = extra_tree_model.predict(feature)\n",
    "acc = accuracy_score(y_true=target, y_pred=training_pred)\n",
    "acc\n",
    "\n",
    "# confusion matrix for training\n",
    "# confusion_matrix(y_true=target, y_pred=training_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function(dummy_df, start, end, model):\n",
    "    \"\"\"\n",
    "    Takes in dummy dataframe and runs all functions based on given year ranges.\n",
    "    Prints out year and accuracy per time range (3 years ranges)\n",
    "    \"\"\"\n",
    "\n",
    "    full_results = {} # Dictionary for storing all the models and their data\n",
    "\n",
    "    for i in range(start, end - 4):\n",
    "\n",
    "        \n",
    "\n",
    "        start_train = i\n",
    "        end_train = i + 2\n",
    "        df = get_data(dummy_df, start_train, end_train)\n",
    "        feature_train, target_train = split_df(df)\n",
    "        clf = train_v1(df, model)\n",
    "\n",
    "        training_pred = clf.predict(feature_train)\n",
    "        #print(start_train, \"-\", end_train, \": \")#, accuracy_score(y_true=target, y_pred=training_pred)) \n",
    "\n",
    "        # Test\n",
    "        start_test = i + 3\n",
    "        end_test = start_test + 2\n",
    "        test = get_data(dummy_df, start_test, end_test)\n",
    "        feature_test, target_test = split_df(test)\n",
    "        testing_pred = clf.predict(feature_test)\n",
    "        #testing_proba_preds = clf.predict_proba(feature_test)[::,1]\n",
    "        #print(start_test, \"-\", end_test, \": \", accuracy_score(y_true=target_test, y_pred=testing_pred))\n",
    "        \n",
    "        print(start_train, \"-\", end_test, \": \")#, accuracy_score(y_true=target, y_pred=training_pred)) \n",
    "\n",
    "\n",
    "        # Print out break and non break accuracy's rather total full accuracy\n",
    "        cm = confusion_matrix(y_true=target_test, y_pred=testing_pred)\n",
    "        # nonbreak_acc = cm[0,0] / (cm[0,0] + cm[0,1])\n",
    "        # print('Non-break accuracy: ', nonbreak_acc)\n",
    "        # break_acc = cm[1,1] / (cm[1, 0] + cm[1,1])\n",
    "        # print('Break accuracy: ', break_acc)\n",
    "\n",
    "        #print out metrics\n",
    "        # precision, recall, f1, support = precision_recall_fscore_support(y_true=target_test, y_pred=testing_pred)\n",
    "        # print('Precision: ', precision)\n",
    "        # print('Recall: ', recall)\n",
    "        # print('F1 Score: ', f1)\n",
    "        # print('Support: ', support)\n",
    "\n",
    "        precision = precision_score(y_true=target_test, y_pred=testing_pred)\n",
    "        recall = recall_score(y_true=target_test, y_pred=testing_pred)\n",
    "        bal_acc = balanced_accuracy_score(y_true=target_test, y_pred=testing_pred)\n",
    "        print('precision: ', precision)\n",
    "        print('recall: ', recall)\n",
    "        print('Balanced accuracy: ', bal_acc)\n",
    "        \n",
    "        print()\n",
    "\n",
    "        model_results = {\n",
    "            'model': clf,\n",
    "            'start_year': start_test,\n",
    "            'end_year': end_test,\n",
    "            'test_df': feature_test, # For eventual SHAP calculations\n",
    "            'target_values': target_test,\n",
    "            'test_predictions': testing_pred,\n",
    "            'confusion_matrix': cm\n",
    "\n",
    "            }\n",
    "\n",
    "        full_results['model_' + str(start_test) + '-' + str(end_test)] = model_results\n",
    "    \n",
    "    return full_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2009 - 2014 : \n",
      "precision:  1.0\n",
      "recall:  0.5988700564971752\n",
      "Balanced accuracy:  0.7994350282485876\n",
      "\n",
      "2010 - 2015 : \n",
      "precision:  1.0\n",
      "recall:  0.544839255499154\n",
      "Balanced accuracy:  0.772419627749577\n",
      "\n",
      "2011 - 2016 : \n",
      "precision:  1.0\n",
      "recall:  0.5924092409240924\n",
      "Balanced accuracy:  0.7962046204620462\n",
      "\n",
      "2012 - 2017 : \n",
      "precision:  1.0\n",
      "recall:  0.5567484662576687\n",
      "Balanced accuracy:  0.7783742331288344\n",
      "\n",
      "2013 - 2018 : \n",
      "precision:  1.0\n",
      "recall:  0.586490939044481\n",
      "Balanced accuracy:  0.7932454695222405\n",
      "\n",
      "2014 - 2019 : \n",
      "precision:  1.0\n",
      "recall:  0.571917808219178\n",
      "Balanced accuracy:  0.785958904109589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbt = GradientBoostingClassifier() # ~58% accuracy\n",
    "ada = AdaBoostClassifier() # 45-52% accuracy\n",
    "#stc = StackingClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "bag = BaggingClassifier()\n",
    "etc = ExtraTreesClassifier()#max_depth=100, max_features='log2', n_estimators=100) # ~58% accuracy\n",
    "\n",
    "results = main_function(dummy_df, 2009, 2019, cv_model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['model_2012-2014', 'model_2013-2015', 'model_2014-2016', 'model_2015-2017', 'model_2016-2018', 'model_2017-2019'])\n"
     ]
    }
   ],
   "source": [
    "print(results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=ExtraTreesClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 100, 300, 500],\n",
       "                                        'max_features': ['log2', 'sqrt',\n",
       "                                                         'auto'],\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500]},\n",
       "                   scoring='recall')"
      ]
     },
     "metadata": {},
     "execution_count": 144
    }
   ],
   "source": [
    "param_grid = {'max_depth': [None, 100, 300, 500],\n",
    "    'max_features': ['log2', 'sqrt', 'auto'],\n",
    "    'n_estimators': [100, 200, 300, 400, 500]\n",
    "    }\n",
    "\n",
    "\n",
    "cv_model = RandomizedSearchCV(estimator=etc, param_distributions=param_grid, scoring='recall', n_iter=10, n_jobs=-1)\n",
    "\n",
    "X_df, y_df = split_df(train_df)\n",
    "cv_model.fit(X_df, y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'n_estimators': 400, 'max_features': 'auto', 'max_depth': 300}"
      ]
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "source": [
    "cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5418181818181819"
      ]
     },
     "metadata": {},
     "execution_count": 146
    }
   ],
   "source": [
    "cv_model.best_score_"
   ]
  },
  {
   "source": [
    "Look at SHAP values, and feature importance values, to determine what is influecing the model most"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(cv_model.best_estimator_)\n",
    "shap_values = explainer.shap_values(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_inds = np.argsort([-np.abs(shap_values[i]).mean() for i in range(len(shap_values))])\n",
    "cmap = plt_colors.ListedColormap(np.array(colors)[class_inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_df, class_names=np.array(y_df.values.unique()), max_display=15, title='Total SHAP Values')"
   ]
  }
 ]
}