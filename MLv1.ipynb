{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  DWW_Mainlines__Permitted_Use__MNL_FEAT_1  \\\n",
       "0                                 Mainline   \n",
       "1                                 Mainline   \n",
       "2                                 Mainline   \n",
       "3                                 Mainline   \n",
       "4                                 Mainline   \n",
       "\n",
       "  DWW_Mainlines__Permitted_Use__MNL_MATE_1  \\\n",
       "0                                 Concrete   \n",
       "1                                 Concrete   \n",
       "2                                 Concrete   \n",
       "3                           Vitrified Clay   \n",
       "4                 Reinforced Concrete Pipe   \n",
       "\n",
       "   DWW_Mainlines__Permitted_Use__MNL_LENGTH  \\\n",
       "0                                    314.79   \n",
       "1                                    363.39   \n",
       "2                                    323.51   \n",
       "3                                    329.13   \n",
       "4                                    273.64   \n",
       "\n",
       "  DWW_Mainlines__Permitted_Use__MNL_INSTAL  Pipe_widths_Width    NEAR_DIST  \\\n",
       "0                         1/1/1972 0:00:00                8.0  3964.600720   \n",
       "1                         1/1/1972 0:00:00                8.0  3609.210948   \n",
       "2                         1/1/1972 0:00:00                8.0  3451.254435   \n",
       "3                         1/1/1928 0:00:00               12.0   833.915482   \n",
       "4                         1/1/1928 0:00:00               18.0   852.426502   \n",
       "\n",
       "   MUSYM  ARTCLASS  BLOCKNBR  SPEEDLIMIT  SURFACEWID SURFACETYP  SLOPE_PCT  \\\n",
       "0   3055       2.0    9400.0        25.0        40.0        PCC        0.0   \n",
       "1   3056       0.0       0.0        20.0        46.0         AC        4.0   \n",
       "2   3056       0.0       0.0        20.0        46.0         AC        4.0   \n",
       "3   3056       0.0    5100.0        20.0         0.0         ST        6.0   \n",
       "4   3056       2.0   10300.0        25.0        42.0     AC/PCC        4.0   \n",
       "\n",
       "  Size DATE  \n",
       "0  NaN  NaN  \n",
       "1  NaN  NaN  \n",
       "2  NaN  NaN  \n",
       "3  NaN  NaN  \n",
       "4  NaN  NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DWW_Mainlines__Permitted_Use__MNL_FEAT_1</th>\n      <th>DWW_Mainlines__Permitted_Use__MNL_MATE_1</th>\n      <th>DWW_Mainlines__Permitted_Use__MNL_LENGTH</th>\n      <th>DWW_Mainlines__Permitted_Use__MNL_INSTAL</th>\n      <th>Pipe_widths_Width</th>\n      <th>NEAR_DIST</th>\n      <th>MUSYM</th>\n      <th>ARTCLASS</th>\n      <th>BLOCKNBR</th>\n      <th>SPEEDLIMIT</th>\n      <th>SURFACEWID</th>\n      <th>SURFACETYP</th>\n      <th>SLOPE_PCT</th>\n      <th>Size</th>\n      <th>DATE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Mainline</td>\n      <td>Concrete</td>\n      <td>314.79</td>\n      <td>1/1/1972 0:00:00</td>\n      <td>8.0</td>\n      <td>3964.600720</td>\n      <td>3055</td>\n      <td>2.0</td>\n      <td>9400.0</td>\n      <td>25.0</td>\n      <td>40.0</td>\n      <td>PCC</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Mainline</td>\n      <td>Concrete</td>\n      <td>363.39</td>\n      <td>1/1/1972 0:00:00</td>\n      <td>8.0</td>\n      <td>3609.210948</td>\n      <td>3056</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n      <td>46.0</td>\n      <td>AC</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Mainline</td>\n      <td>Concrete</td>\n      <td>323.51</td>\n      <td>1/1/1972 0:00:00</td>\n      <td>8.0</td>\n      <td>3451.254435</td>\n      <td>3056</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n      <td>46.0</td>\n      <td>AC</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Mainline</td>\n      <td>Vitrified Clay</td>\n      <td>329.13</td>\n      <td>1/1/1928 0:00:00</td>\n      <td>12.0</td>\n      <td>833.915482</td>\n      <td>3056</td>\n      <td>0.0</td>\n      <td>5100.0</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>ST</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Mainline</td>\n      <td>Reinforced Concrete Pipe</td>\n      <td>273.64</td>\n      <td>1/1/1928 0:00:00</td>\n      <td>18.0</td>\n      <td>852.426502</td>\n      <td>3056</td>\n      <td>2.0</td>\n      <td>10300.0</td>\n      <td>25.0</td>\n      <td>42.0</td>\n      <td>AC/PCC</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df = pd.read_csv(\"Pipes_Break20.csv\")\n",
    "\n",
    "df.columns\n",
    "# select non join columns and ML needed columns\n",
    "columns = ['DWW_Mainlines__Permitted_Use__MNL_FEAT_1', 'DWW_Mainlines__Permitted_Use__MNL_MATE_1', \n",
    "       'DWW_Mainlines__Permitted_Use__MNL_LENGTH', 'DWW_Mainlines__Permitted_Use__MNL_INSTAL',\n",
    "       'Pipe_widths_Width', 'NEAR_DIST', 'MUSYM', 'ARTCLASS', 'BLOCKNBR', \n",
    "       'SPEEDLIMIT', 'SURFACEWID', 'SURFACETYP', 'SLOPE_PCT', 'Size', 'DATE']\n",
    "non_joins = df[columns]\n",
    "non_joins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only years\n",
    "non_joins['DWW_Mainlines__Permitted_Use__MNL_INSTAL'] = pd.to_datetime(non_joins['DWW_Mainlines__Permitted_Use__MNL_INSTAL'], format='%m/%d/%Y %H:%M:%S')\n",
    "non_joins['DWW_Mainlines__Permitted_Use__MNL_INSTAL'] = non_joins['DWW_Mainlines__Permitted_Use__MNL_INSTAL'].map(lambda x: x.year)\n",
    "\n",
    "non_joins['DATE'] = pd.to_datetime(non_joins['DATE'], format='%m/%d/%Y %H:%M:%S')\n",
    "non_joins['DATE'] = non_joins['DATE'].map(lambda x: x.year)\n",
    "\n",
    "#non_joins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out NaN from DATE col\n",
    "breaks_df = non_joins[non_joins['DATE'].notna()]\n",
    "# set size column to width column and drop size \n",
    "breaks_df['Pipe_widths_Width'] = breaks_df['Size']\n",
    "breaks_df = breaks_df.drop('Size', axis=1)\n",
    "# breaks_df.head()"
   ]
  },
  {
   "source": [
    "## ML Pseudo Steps\n",
    "#### 1) assign binary variable --> can be raw data set\n",
    "#### 2) create dummy variables for categorical columns\n",
    "* make sure soil column ['MUSYM'] is categorical\n",
    "#### 3) list of years (and cycle through those)\n",
    "#### 4) will have six year groups :\n",
    "* train on [2009, 2010, 2011], test on [2012, 2013, 2014]\n",
    "* move onto [2010, 2011, 2012], test on [2013, 2014, 2015], etc ...\n",
    "#### 5) create function to create subset of data\n",
    "* want to include where there is NOT a break year (those will be our non-broken positive examples)\n",
    "* want to include where break year is in time frame of what we want\n",
    "* exclude installs AFTER time frame window\n",
    "* based on time window, calculate appropriate age of pipes \n",
    "    * (select beginning year of time frame --> ex: [2009, 2010, 2011] subtract install year from 2009)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_df = non_joins\n",
    "# pseudo_df.head()\n",
    "\n",
    "# fill Nan with 0 (idk why, but it just made it work FOR NOW)\n",
    "# if date is not 0 (NaN), make width = size \n",
    "# then for all df, drop size column\n",
    "\n",
    "pseudo_df['DATE'] = pseudo_df['DATE'].fillna(0)\n",
    "pseudo_df.loc[pseudo_df['DATE'] != 0, ['Pipe_widths_Width']] = pseudo_df['Size']\n",
    "pseudo_df = pseudo_df.drop('Size', axis=1)\n",
    "# pseudo_df.head()\n",
    "\n",
    "# change 'Width' values to numbers instead of strings (for dummy prep)\n",
    "pseudo_df['Width'] = pd.to_numeric(pseudo_df['Pipe_widths_Width'], errors='coerce')\n",
    "# pseudo_df['Width'].unique()\n",
    "\n",
    "# Assign binary variables:\n",
    "# [Create new column] If pipe has a broken date --> broken pipes = 0, non-broken pipes = 1\n",
    "pseudo_df['TARGET'] = pseudo_df['DATE'].apply(lambda x: 1 if x == 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables\n",
    "dummy_df = pd.get_dummies(pseudo_df)\n",
    "# test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df, start, end):\n",
    "    \"\"\"\n",
    "    Takes in df and filters depending on timeframe (start and end years).\n",
    "    Returns subset of data for training in timeframe.\n",
    "    \"\"\"\n",
    "    # want to include where there is NOT a break year (those will be our non-broken positive examples --> 'DATE' == 0) - DATE col\n",
    "    # want to include where break year is in time frame of what we want - DATE col\n",
    "    train_df = df[(df['DATE'] == 0 )| ((df['DATE'] >= start) & (df['DATE'] <= end))]\n",
    "\n",
    "    # exclude installs AFTER time frame window - MNL_INSTAL col\n",
    "    train_df = train_df[(train_df['DWW_Mainlines__Permitted_Use__MNL_INSTAL'] <= end)]\n",
    "\n",
    "    # based on time window, calculate appropriate age of pipes (select beginning year of time frame --> ex: 2009, 2010, 2011\n",
    "    #       subtract install year from 2009) - MNL_INSTAL col\n",
    "    # -- will create negative numbers\n",
    "    train_df['AGE'] = start - train_df['DWW_Mainlines__Permitted_Use__MNL_INSTAL']\n",
    "\n",
    "    return train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_data(dummy_df, 2009, 2011)\n",
    "# train_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trains\n",
    "# tests\n",
    "# move over\n",
    "# rinse & repeat until 2019\n",
    "def split_df(df):\n",
    "    \"\"\"\n",
    "    \"\"\"    \n",
    "    df = df.dropna()\n",
    "    feature_df = df.drop(['TARGET', 'DATE'], axis=1)\n",
    "    target_df = df[['TARGET']]\n",
    "\n",
    "    return feature_df, target_df\n",
    "\n",
    "def train_v1(df):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    feature, target = split_df(df)\n",
    "    etc = ExtraTreesClassifier()\n",
    "    etc.fit(feature, target)\n",
    "\n",
    "    return etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# Training data with ExtraTreesClassifier and split data\n",
    "extra_tree_model = train_v1(train_df)\n",
    "feature, target = split_df(train_df)\n",
    "\n",
    "# running a prediction model on training set\n",
    "training_pred = extra_tree_model.predict(feature)\n",
    "acc = accuracy_score(y_true=target, y_pred=training_pred)\n",
    "acc\n",
    "\n",
    "# confusion matrix for training\n",
    "# confusion_matrix(y_true=target, y_pred=training_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing on next years\n",
    "test_2012 = get_data(dummy_df, 2012, 2014)\n",
    "feature_2012, target_2012 = split_df(test_2012)\n",
    "\n",
    "testing_pred_2012 = extra_tree_model.predict(feature_2012)\n",
    "acc = accuracy_score(y_true=target_2012, y_pred=testing_pred_2012)\n",
    "\n",
    "cm = confusion_matrix(y_true=target_2012, y_pred=testing_pred_2012)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5986394557823129"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "cm[0,0] / (cm[0,0] + cm[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function(dummy_df, start, end):\n",
    "    \"\"\"\n",
    "    Takes in dummy dataframe and runs all functions based on given year ranges.\n",
    "    Prints out year and accuracy per time range (3 years ranges)\n",
    "    \"\"\"\n",
    "    for i in range(start, end - 4):\n",
    "        start_train = i\n",
    "        end_train = i + 2\n",
    "        df = get_data(dummy_df, start_train, end_train)\n",
    "        feature_train, target_train = split_df(df)\n",
    "        extra_tree_model = train_v1(df)\n",
    "\n",
    "        training_pred = extra_tree_model.predict(feature)\n",
    "        #print(start_train, \"-\", end_train, \": \", accuracy_score(y_true=target, y_pred=training_pred)) \n",
    "\n",
    "        # Test\n",
    "        start_test = i + 3\n",
    "        end_test = start_test + 2\n",
    "        test = get_data(dummy_df, start_test, end_test)\n",
    "        feature_test, target_test = split_df(test)\n",
    "        testing_pred = extra_tree_model.predict(feature_test)\n",
    "        #print(start_test, \"-\", end_test, \": \", accuracy_score(y_true=target_test, y_pred=testing_pred))\n",
    "        \n",
    "        # Print out break and non break accuracy's rather total full accuracy\n",
    "        cm = confusion_matrix(y_true=target_test, y_pred=testing_pred)\n",
    "        break_acc = cm[0,0] / (cm[0,0] + cm[0,1])\n",
    "        print('Break accuracy: ', break_acc)\n",
    "        nonbreak_acc = cm[1,1] / (cm[1, 0] + cm[1,1])\n",
    "        print('Non-breal accuracy: ', nonbreak_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Break accuracy:  0.5986394557823129\n",
      "Non-breal accuracy:  1.0\n",
      "Break accuracy:  0.5738498789346247\n",
      "Non-breal accuracy:  1.0\n",
      "Break accuracy:  0.6211401425178147\n",
      "Non-breal accuracy:  1.0\n",
      "Break accuracy:  0.5989010989010989\n",
      "Non-breal accuracy:  1.0\n",
      "Break accuracy:  0.6025200458190149\n",
      "Non-breal accuracy:  1.0\n",
      "Break accuracy:  0.6052009456264775\n",
      "Non-breal accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "main_function(dummy_df, 2009, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}