{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"FinalFinal.csv\")\n",
    "\n",
    "df.columns\n",
    "# select non join columns and ML needed columns\n",
    "columns = ['MNL_FEAT_1', 'MNL_MATE_1', 'MNL_LENGTH', 'MNL_INSTAL',\n",
    "       'Width', 'NEAR_DIST', 'MUSYM', 'ARTCLASS', 'BLOCKNBR', \n",
    "       'SPEEDLIMIT', 'SURFACEWID', 'SURFACETYP', 'SLOPE_PCT', 'Size', 'DATE']\n",
    "non_joins = df[columns]\n",
    "# non_joins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only years\n",
    "non_joins['MNL_INSTAL'] = pd.to_datetime(non_joins['MNL_INSTAL'], format='%m/%d/%Y %H:%M:%S')\n",
    "non_joins['MNL_INSTAL'] = non_joins['MNL_INSTAL'].map(lambda x: x.year)\n",
    "\n",
    "non_joins['DATE'] = pd.to_datetime(non_joins['DATE'], format='%m/%d/%Y %H:%M:%S')\n",
    "non_joins['DATE'] = non_joins['DATE'].map(lambda x: x.year)\n",
    "\n",
    "#non_joins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out NaN from DATE col\n",
    "breaks_df = non_joins[non_joins['DATE'].notna()]\n",
    "# set size column to width column and drop size \n",
    "breaks_df['Width'] = breaks_df['Size']\n",
    "breaks_df = breaks_df.drop('Size', axis=1)\n",
    "# breaks_df.head()"
   ]
  },
  {
   "source": [
    "## ML Pseudo Steps\n",
    "#### 1) assign binary variable --> can be raw data set\n",
    "#### 2) create dummy variables for categorical columns\n",
    "* make sure soil column ['MUSYM'] is categorical\n",
    "#### 3) list of years (and cycle through those)\n",
    "#### 4) will have six year groups :\n",
    "* train on [2009, 2010, 2011], test on [2012, 2013, 2014]\n",
    "* move onto [2010, 2011, 2012], test on [2013, 2014, 2015], etc ...\n",
    "#### 5) create function to create subset of data\n",
    "* want to include where there is NOT a break year (those will be our non-broken positive examples)\n",
    "* want to include where break year is in time frame of what we want\n",
    "* exclude installs AFTER time frame window\n",
    "* based on time window, calculate appropriate age of pipes \n",
    "    * (select beginning year of time frame --> ex: [2009, 2010, 2011] subtract install year from 2009)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_df = non_joins\n",
    "# pseudo_df.head()\n",
    "\n",
    "# fill Nan with 0 (idk why, but it just made it work FOR NOW)\n",
    "# if date is not 0 (NaN), make width = size \n",
    "# then for all df, drop size column\n",
    "\n",
    "pseudo_df['DATE'] = pseudo_df['DATE'].fillna(0)\n",
    "pseudo_df.loc[pseudo_df['DATE'] != 0, ['Width']] = pseudo_df['Size']\n",
    "pseudo_df = pseudo_df.drop('Size', axis=1)\n",
    "# pseudo_df.head()\n",
    "\n",
    "# change 'Width' values to numbers instead of strings (for dummy prep)\n",
    "pseudo_df['Width'] = pd.to_numeric(pseudo_df['Width'], errors='coerce')\n",
    "# pseudo_df['Width'].unique()\n",
    "\n",
    "# Assign binary variables:\n",
    "# [Create new column] If pipe has a broken date --> broken pipes = 0, non-broken pipes = 1\n",
    "pseudo_df['TARGET'] = pseudo_df['DATE'].apply(lambda x: 1 if x == 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables\n",
    "dummy_df = pd.get_dummies(pseudo_df)\n",
    "# test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df, start, end):\n",
    "    \"\"\"\n",
    "    Takes in df and filters depending on timeframe (start and end years).\n",
    "    Returns subset of data for training in timeframe.\n",
    "    \"\"\"\n",
    "    # want to include where there is NOT a break year (those will be our non-broken positive examples --> 'DATE' == 0) - DATE col\n",
    "    # want to include where break year is in time frame of what we want - DATE col\n",
    "    train_df = df[(df['DATE'] == 0 )| ((df['DATE'] >= start) & (df['DATE'] <= end))]\n",
    "\n",
    "    # exclude installs AFTER time frame window - MNL_INSTAL col\n",
    "    train_df = train_df[(train_df['MNL_INSTAL'] <= end)]\n",
    "\n",
    "    # based on time window, calculate appropriate age of pipes (select beginning year of time frame --> ex: 2009, 2010, 2011\n",
    "    #       subtract install year from 2009) - MNL_INSTAL col\n",
    "    # -- will create negative numbers\n",
    "    train_df['AGE'] = start - train_df['MNL_INSTAL']\n",
    "\n",
    "    return train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_data(dummy_df, 2009, 2011)\n",
    "# train_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trains\n",
    "# tests\n",
    "# move over\n",
    "# rinse & repeat until 2019\n",
    "def split_df(df):\n",
    "    \"\"\"\n",
    "    \"\"\"    \n",
    "    df = df.dropna()\n",
    "    feature_df = df.drop(['TARGET', 'DATE'], axis=1)\n",
    "    target_df = df[['TARGET']]\n",
    "\n",
    "    return feature_df, target_df\n",
    "\n",
    "def train_v1(df):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    feature, target = split_df(df)\n",
    "    etc = ExtraTreesClassifier()\n",
    "    etc.fit(feature, target)\n",
    "\n",
    "    return etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "# Training data with ExtraTreesClassifier and split data\n",
    "extra_tree_model = train_v1(train_df)\n",
    "feature, target = split_df(train_df)\n",
    "\n",
    "# running a prediction model on training set\n",
    "training_pred = extra_tree_model.predict(feature)\n",
    "acc = accuracy_score(y_true=target, y_pred=training_pred)\n",
    "acc\n",
    "\n",
    "# confusion matrix for training\n",
    "# confusion_matrix(y_true=target, y_pred=training_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9731478260869565"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "# testing on next years\n",
    "test_2012 = get_data(dummy_df, 2012, 2014)\n",
    "feature_2012, target_2012 = split_df(test_2012)\n",
    "\n",
    "testing_pred_2012 = extra_tree_model.predict(feature_2012)\n",
    "acc = accuracy_score(y_true=target_2012, y_pred=testing_pred_2012)\n",
    "\n",
    "# confusion_matrix(y_true=target_2012, y_pred=testing_pred_2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function(dummy_df, start, end):\n",
    "    \"\"\"\n",
    "    Takes in dummy dataframe and runs all functions based on given year ranges.\n",
    "    Prints out year and accuracy per time range (3 years ranges)\n",
    "    \"\"\"\n",
    "    for i in range(start, end - 4):\n",
    "        start_train = i\n",
    "        end_train = i + 2\n",
    "        df = get_data(dummy_df, start_train, end_train)\n",
    "        feature_train, target_train = split_df(df)\n",
    "        extra_tree_model = train_v1(df)\n",
    "\n",
    "        training_pred = extra_tree_model.predict(feature)\n",
    "        print(start_train, \"-\", end_train, \": \", accuracy_score(y_true=target, y_pred=training_pred)) \n",
    "\n",
    "        # Test\n",
    "        start_test = i + 3\n",
    "        end_test = start_test + 2\n",
    "        test = get_data(dummy_df, start_test, end_test)\n",
    "        feature_test, target_test = split_df(test)\n",
    "        testing_pred = extra_tree_model.predict(feature_test)\n",
    "        print(start_test, \"-\", end_test, \": \", accuracy_score(y_true=target_test, y_pred=testing_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2009 - 2011 :  1.0\n",
      "2012 - 2014 :  0.9732347826086957\n",
      "2010 - 2012 :  0.9944101258611788\n",
      "2013 - 2015 :  0.9717936271280468\n",
      "2011 - 2013 :  0.993021558399943\n",
      "2014 - 2016 :  0.974964457852214\n",
      "2012 - 2014 :  0.9908140921795169\n",
      "2015 - 2017 :  0.9755629345231919\n",
      "2013 - 2015 :  0.9906716750040054\n",
      "2016 - 2018 :  0.9785052394561358\n",
      "2014 - 2016 :  0.9906538728570665\n",
      "2017 - 2019 :  0.979710396254227\n",
      "2015 - 2017 :  0.9904224449468606\n",
      "2018 - 2020 :  0.9822378254371025\n",
      "2016 - 2018 :  0.9905826642693109\n",
      "2019 - 2021 :  0.9887457555921167\n"
     ]
    }
   ],
   "source": [
    "main_function(dummy_df, 2009, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}