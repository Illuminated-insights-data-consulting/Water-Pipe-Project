{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# # fit model no training data\n",
    "# model = XGBClassifier()\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # make predictions for test data\n",
    "# y_pred = model.predict(X_test)\n",
    "# predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# # see accuracy of model\n",
    "# accuracy = accuracy_score(y_test, predictions)\n",
    "# print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# for xgboost \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, average_precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"FinalFinal.csv\")\n",
    "\n",
    "df.columns\n",
    "# select non join columns and ML needed columns\n",
    "columns = ['MNL_FEAT_1', 'MNL_MATE_1', 'MNL_LENGTH', 'MNL_INSTAL',\n",
    "       'Width', 'NEAR_DIST', 'MUSYM', 'ARTCLASS', 'BLOCKNBR', \n",
    "       'SPEEDLIMIT', 'SURFACEWID', 'SURFACETYP', 'SLOPE_PCT', 'Size', 'DATE']\n",
    "non_joins = df[columns]\n",
    "# non_joins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only years\n",
    "non_joins['MNL_INSTAL'] = pd.to_datetime(non_joins['MNL_INSTAL'], format='%m/%d/%Y %H:%M:%S')\n",
    "non_joins['MNL_INSTAL'] = non_joins['MNL_INSTAL'].map(lambda x: x.year)\n",
    "\n",
    "non_joins['DATE'] = pd.to_datetime(non_joins['DATE'], format='%m/%d/%Y %H:%M:%S')\n",
    "non_joins['DATE'] = non_joins['DATE'].map(lambda x: x.year)\n",
    "\n",
    "#non_joins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out NaN from DATE col\n",
    "breaks_df = non_joins[non_joins['DATE'].notna()]\n",
    "# set size column to width column and drop size \n",
    "breaks_df['Width'] = breaks_df['Size']\n",
    "breaks_df = breaks_df.drop('Size', axis=1)\n",
    "# breaks_df.head()"
   ]
  },
  {
   "source": [
    "## ML Pseudo Steps\n",
    "#### 1) assign binary variable --> can be raw data set\n",
    "#### 2) create dummy variables for categorical columns\n",
    "* make sure soil column ['MUSYM'] is categorical\n",
    "#### 3) list of years (and cycle through those)\n",
    "#### 4) will have six year groups :\n",
    "* train on [2009, 2010, 2011], test on [2012, 2013, 2014]\n",
    "* move onto [2010, 2011, 2012], test on [2013, 2014, 2015], etc ...\n",
    "#### 5) create function to create subset of data\n",
    "* want to include where there is NOT a break year (those will be our non-broken positive examples)\n",
    "* want to include where break year is in time frame of what we want\n",
    "* exclude installs AFTER time frame window\n",
    "* based on time window, calculate appropriate age of pipes \n",
    "    * (select beginning year of time frame --> ex: [2009, 2010, 2011] subtract install year from 2009)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_df = non_joins\n",
    "# pseudo_df.head()\n",
    "\n",
    "# fill Nan with 0 (idk why, but it just made it work FOR NOW)\n",
    "# if date is not 0 (NaN), make width = size \n",
    "# then for all df, drop size column\n",
    "\n",
    "pseudo_df['DATE'] = pseudo_df['DATE'].fillna(0)\n",
    "pseudo_df.loc[pseudo_df['DATE'] != 0, ['Width']] = pseudo_df['Size']\n",
    "pseudo_df = pseudo_df.drop('Size', axis=1)\n",
    "# pseudo_df.head()\n",
    "\n",
    "# change 'Width' values to numbers instead of strings (for dummy prep)\n",
    "pseudo_df['Width'] = pd.to_numeric(pseudo_df['Width'], errors='coerce')\n",
    "# pseudo_df['Width'].unique()\n",
    "\n",
    "# Assign binary variables:\n",
    "# [Create new column] If pipe has a broken date --> broken pipes = 0, non-broken pipes = 1\n",
    "pseudo_df['TARGET'] = pseudo_df['DATE'].apply(lambda x: 1 if x == 0 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo_df = pseudo_df.drop('DATE', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   MNL_LENGTH  MNL_INSTAL  ...  SURFACETYP_PCC  SURFACETYP_ST\n",
       "0      314.79        1972  ...               1              0\n",
       "1      363.39        1972  ...               0              0\n",
       "2      323.51        1972  ...               0              0\n",
       "3      329.13        1928  ...               0              1\n",
       "4      273.64        1928  ...               0              0\n",
       "\n",
       "[5 rows x 42 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MNL_LENGTH</th>\n      <th>MNL_INSTAL</th>\n      <th>Width</th>\n      <th>NEAR_DIST</th>\n      <th>MUSYM</th>\n      <th>ARTCLASS</th>\n      <th>BLOCKNBR</th>\n      <th>SPEEDLIMIT</th>\n      <th>SURFACEWID</th>\n      <th>SLOPE_PCT</th>\n      <th>DATE</th>\n      <th>TARGET</th>\n      <th>MNL_FEAT_1_Mainline</th>\n      <th>MNL_FEAT_1_PHANTOM CONNECTOR</th>\n      <th>MNL_FEAT_1_Stub</th>\n      <th>MNL_FEAT_1_Unknown</th>\n      <th>MNL_MATE_1_</th>\n      <th>MNL_MATE_1_Acrylonitrile Butadiene Styrene</th>\n      <th>MNL_MATE_1_Asbestos Cement</th>\n      <th>MNL_MATE_1_Brick</th>\n      <th>MNL_MATE_1_Cast Iron Pipe</th>\n      <th>MNL_MATE_1_Concrete</th>\n      <th>MNL_MATE_1_Corrugated Flexible Plastic</th>\n      <th>MNL_MATE_1_Corrugated Metal Pipe</th>\n      <th>MNL_MATE_1_Corrugated Rigid Plastic</th>\n      <th>MNL_MATE_1_Ductile Iron Pipe</th>\n      <th>MNL_MATE_1_High Density Polyethylene</th>\n      <th>MNL_MATE_1_Other</th>\n      <th>MNL_MATE_1_Polyvinyl Chloride</th>\n      <th>MNL_MATE_1_Reinforced Concrete Box</th>\n      <th>MNL_MATE_1_Reinforced Concrete Pipe</th>\n      <th>MNL_MATE_1_Steel</th>\n      <th>MNL_MATE_1_Unknown</th>\n      <th>MNL_MATE_1_Vitrified Clay</th>\n      <th>MNL_MATE_1_Wood Stave Pipe</th>\n      <th>SURFACETYP_</th>\n      <th>SURFACETYP_AC</th>\n      <th>SURFACETYP_AC/AC</th>\n      <th>SURFACETYP_AC/PCC</th>\n      <th>SURFACETYP_GRAVEL</th>\n      <th>SURFACETYP_PCC</th>\n      <th>SURFACETYP_ST</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>314.79</td>\n      <td>1972</td>\n      <td>8.0</td>\n      <td>3891.620149</td>\n      <td>3055</td>\n      <td>2</td>\n      <td>9400</td>\n      <td>25</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>363.39</td>\n      <td>1972</td>\n      <td>8.0</td>\n      <td>3609.210867</td>\n      <td>3056</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>46</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>323.51</td>\n      <td>1972</td>\n      <td>8.0</td>\n      <td>3451.254202</td>\n      <td>3056</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>46</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>329.13</td>\n      <td>1928</td>\n      <td>12.0</td>\n      <td>771.313134</td>\n      <td>3056</td>\n      <td>0</td>\n      <td>5100</td>\n      <td>20</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>273.64</td>\n      <td>1928</td>\n      <td>18.0</td>\n      <td>833.921160</td>\n      <td>3056</td>\n      <td>2</td>\n      <td>10300</td>\n      <td>25</td>\n      <td>42</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "# Create dummy variables\n",
    "dummy_df = pd.get_dummies(pseudo_df)\n",
    "# test_df.columns\n",
    "dummy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df, start, end):\n",
    "    \"\"\"\n",
    "    Takes in df and filters depending on timeframe (start and end years).\n",
    "    Returns subset of data for training in timeframe.\n",
    "    \"\"\"\n",
    "    # want to include where there is NOT a break year (those will be our non-broken positive examples --> 'DATE' == 0) - DATE col\n",
    "    # want to include where break year is in time frame of what we want - DATE col\n",
    "    train_df = df[(df['DATE'] == 0 )| ((df['DATE'] >= start) & (df['DATE'] <= end))]\n",
    "\n",
    "    # exclude installs AFTER time frame window - MNL_INSTAL col\n",
    "    train_df = train_df[(train_df['MNL_INSTAL'] <= end)]\n",
    "\n",
    "    # based on time window, calculate appropriate age of pipes (select beginning year of time frame --> ex: 2009, 2010, 2011\n",
    "    #       subtract install year from 2009) - MNL_INSTAL col\n",
    "    # -- will create negative numbers\n",
    "    train_df['AGE'] = start - train_df['MNL_INSTAL']\n",
    "\n",
    "    return train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_data(dummy_df, 2009, 2011)\n",
    "# train_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trains\n",
    "# tests\n",
    "# move over\n",
    "# rinse & repeat until 2019\n",
    "def split_df(df):\n",
    "    \"\"\"\n",
    "    \"\"\"    \n",
    "    df = df.dropna()\n",
    "    feature_df = df.drop(['TARGET', 'DATE'], axis=1)\n",
    "    target_df = df[['TARGET']]\n",
    "\n",
    "    return feature_df, target_df\n",
    "\n",
    "def train_v1(df, model):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    feature, target = split_df(df)\n",
    "    etc = ExtraTreesClassifier()\n",
    "    etc.fit(feature, target)\n",
    "\n",
    "    return etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost splitting\n",
    "feature, target = split_df(train_df)\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(feature, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "# fit model on training data\n",
    "model = XGBClassifier()\n",
    "model.fit(feature, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Balanced Accuracy Score: 70.00%\nBalanced Accuracy Score: 99.99%\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, predictions)\n",
    "print(\"Balanced Accuracy Score: %.2f%%\" % (balanced_accuracy * 100.0))\n",
    "\n",
    "recall = recall_score(y_test, predictions)\n",
    "print(\"Recall Score: %.2f%%\" % (recall * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "# Training data with ExtraTreesClassifier and split data\n",
    "extra_tree_model = train_v1(train_df)\n",
    "feature, target = split_df(train_df)\n",
    "\n",
    "# running a prediction model on training set\n",
    "training_pred = extra_tree_model.predict(feature)\n",
    "acc = accuracy_score(y_true=target, y_pred=training_pred)\n",
    "acc\n",
    "\n",
    "# confusion matrix for training\n",
    "# confusion_matrix(y_true=target, y_pred=training_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9731478260869565"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "# testing on next years\n",
    "test_2012 = get_data(dummy_df, 2012, 2014)\n",
    "feature_2012, target_2012 = split_df(test_2012)\n",
    "\n",
    "testing_pred_2012 = extra_tree_model.predict(feature_2012)\n",
    "acc = accuracy_score(y_true=target_2012, y_pred=testing_pred_2012)\n",
    "\n",
    "# confusion_matrix(y_true=target_2012, y_pred=testing_pred_2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function(dummy_df, start, end):\n",
    "    \"\"\"\n",
    "    Takes in dummy dataframe and runs all functions based on given year ranges.\n",
    "    Prints out year and accuracy per time range (3 years ranges)\n",
    "    \"\"\"\n",
    "    for i in range(start, end - 4):\n",
    "        start_train = i\n",
    "        end_train = i + 2\n",
    "        df = get_data(dummy_df, start_train, end_train)\n",
    "        feature_train, target_train = split_df(df)\n",
    "        extra_tree_model = train_v1(df)\n",
    "\n",
    "        training_pred = extra_tree_model.predict(feature)\n",
    "        print(start_train, \"-\", end_train, \": \", accuracy_score(y_true=target, y_pred=training_pred)) \n",
    "\n",
    "        # Test\n",
    "        start_test = i + 3\n",
    "        end_test = start_test + 2\n",
    "        test = get_data(dummy_df, start_test, end_test)\n",
    "        feature_test, target_test = split_df(test)\n",
    "        testing_pred = extra_tree_model.predict(feature_test)\n",
    "        print(start_test, \"-\", end_test, \": \", accuracy_score(y_true=target_test, y_pred=testing_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2009 - 2011 :  1.0\n",
      "2012 - 2014 :  0.9732347826086957\n",
      "2010 - 2012 :  0.9944101258611788\n",
      "2013 - 2015 :  0.9717936271280468\n",
      "2011 - 2013 :  0.993021558399943\n",
      "2014 - 2016 :  0.974964457852214\n",
      "2012 - 2014 :  0.9908140921795169\n",
      "2015 - 2017 :  0.9755629345231919\n",
      "2013 - 2015 :  0.9906716750040054\n",
      "2016 - 2018 :  0.9785052394561358\n",
      "2014 - 2016 :  0.9906538728570665\n",
      "2017 - 2019 :  0.979710396254227\n",
      "2015 - 2017 :  0.9904224449468606\n",
      "2018 - 2020 :  0.9822378254371025\n",
      "2016 - 2018 :  0.9905826642693109\n",
      "2019 - 2021 :  0.9887457555921167\n"
     ]
    }
   ],
   "source": [
    "main_function(dummy_df, 2009, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}